{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719186d8-8e59-4f66-8ee7-88bee7800733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: This model is the facebook's bart model. I want to evaluate it and see how well it summarizes th einformation or a paragraph provided to it.The very first run produced results that were not good at all and instad of shortening the paragraph and providing the summary instead it just paraphrasedor more like changed the order of the sentences. Even added one more sentence by itself which was not nedded at all defeating the purpose of the task itself. So I decided to try a different approach.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "class HuggingFaceSummarizer:\n",
    "    def __init__(self, model_name=\"facebook/bart-large\"):\n",
    "        # Load the tokenizer and model from Hugging Face\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    def generate_summary(self, text: str) -> str:\n",
    "        # Tokenize the input text\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "\n",
    "        # Generate the summary using the model\n",
    "        summary_ids = self.model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_length=150,    # Limit the length of the summary\n",
    "            num_beams=4,       # Beam search to improve the quality of the summary\n",
    "            length_penalty=2.0,  # Penalty to discourage long summaries\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode the summary and return\n",
    "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "\n",
    "# Create an instance of the summarizer\n",
    "summarizer_llm = HuggingFaceSummarizer()\n",
    "\n",
    "# Example input text to summarize\n",
    "input_text = \"\"\"\n",
    "This model is the facebook's bart model. I want to evaluate it and see how well it summarizes th einformation or a paragraph provided to it.\n",
    "The very first run produced results that were not good at all and instad of shortening the paragraph and providing the summary instead it just paraphrased\n",
    "or more like changed the order of the sentences. Even added one more sentence by itself which was not nedded at all defeating the purpose of the task itself.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarizer_llm.generate_summary(input_text)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd8161-e177-464e-ba03-56d2b7499eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
